{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07264f09-ef47-40bf-b161-68b1e1697ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dxdata\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize dxdata engine\n",
    "engine = dxdata.connect(dialect=\"hive+pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e23bda-3e5d-41f8-a27a-10125b2b2a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = os.popen(\"dx env | grep project- | awk -F '\\t' '{print $2}'\").read().rstrip()\n",
    "record = os.popen(\"dx describe *dataset | grep  record- | awk -F ' ' '{print $2}'\").read().rstrip().split('\\n')[0]\n",
    "DATASET_ID = project + \":\" + record\n",
    "dataset = dxdata.load_dataset(id=DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251038d2-a0b6-4650-85c6-8d192cb02044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = dataset['participant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049c70e-8c6c-45da-9278-4e5237976a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "# Find by field name\n",
    "field_eid = pheno.find_field(name=\"eid\")\n",
    "\n",
    "# Find by exact title\n",
    "field_sex = pheno.find_field(title=\"Sex\")\n",
    "field_age = pheno.find_field(title=\"Age at recruitment\")\n",
    "field_height = pheno.find_field(title=\"Standing height | Instance 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572963c6-5666-426c-b051-231408b37aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Field \"eid\">, <Field \"p50_i0\">, <Field \"p31\">, <Field \"p21022\">]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_list = [field_eid, field_height, field_sex, field_age]\n",
    "field_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72d1a6-d421-4cbe-9b03-323ccade47b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## prepare recorders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca09f190-1802-4a6a-b596-01f51922963c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all_fields = pd.DataFrame(columns = ['entity','field_name','filed_title'])\n",
    "for entity in dataset.entities:\n",
    "    entity_name  = entity.name\n",
    "    \n",
    "    for field in entity.fields:\n",
    "        field_name = field.name\n",
    "        filed_title = field.title\n",
    "        df_all_fields.loc[len(df_all_fields),] = [entity_name,field_name,filed_title]\n",
    "df_all_fields['downloaded']=[False]*len(df_all_fields)\n",
    "df_all_fields.to_csv('recorder_all_fields.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de0b65db-3e49-45db-8d51-bb3badb867ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for entity in df_all_fields['entity'].unique():\n",
    "    df_target_entity = df_all_fields.loc[df_all_fields['entity']==entity,]\n",
    "    df_target_entity.to_csv(f'recorder_{entity}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76eb51-469d-4cf3-a893-48b2820e8025",
   "metadata": {
    "tags": []
   },
   "source": [
    "# data downloading codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd30fd-76d7-4dfa-98e6-fab470d03b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 52,68 is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef79d404-e60c-45c0-b5e1-d882de2a89d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([52, 68, 179, 815, 816, 820, 828], 931)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fail_list,ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c7bc0f2-091e-40c0-bb7d-44f78f998b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity='participant'\n",
    "ind = 931\n",
    "interval = 100\n",
    "bulk_num = 30\n",
    "fail_list = [52, 68, 179, 815, 816, 820, 828]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f0bee-6204-4125-a55c-9c40e5574e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now download bulk 931, from 27931 to 27960\n",
      "now download bulk 932, from 27961 to 27990\n",
      "now download bulk 933, from 27991 to 28020\n",
      "now download bulk 934, from 28021 to 28050\n",
      "now download bulk 935, from 28051 to 28080\n",
      "now download bulk 936, from 28081 to 28110\n",
      "now download bulk 937, from 28111 to 28140\n",
      "now download bulk 938, from 28141 to 28170\n",
      "now download bulk 939, from 28171 to 28200\n",
      "now download bulk 940, from 28201 to 28230\n",
      "now download bulk 941, from 28231 to 28260\n",
      "now download bulk 942, from 28261 to 28290\n",
      "now download bulk 943, from 28291 to 28320\n",
      "now download bulk 944, from 28321 to 28350\n",
      "now download bulk 945, from 28351 to 28380\n",
      "now download bulk 946, from 28381 to 28410\n",
      "now download bulk 947, from 28411 to 28440\n",
      "now download bulk 948, from 28441 to 28470\n",
      "now download bulk 949, from 28471 to 28500\n",
      "now download bulk 950, from 28501 to 28530\n",
      "now download bulk 951, from 28531 to 28560\n",
      "now download bulk 952, from 28561 to 28590\n",
      "now download bulk 953, from 28591 to 28620\n",
      "now download bulk 954, from 28621 to 28650\n",
      "now download bulk 955, from 28651 to 28680\n",
      "now download bulk 956, from 28681 to 28710\n",
      "now download bulk 957, from 28711 to 28740\n",
      "now download bulk 958, from 28741 to 28770\n",
      "now download bulk 959, from 28771 to 28800\n",
      "now download bulk 960, from 28801 to 28830\n",
      "now download bulk 961, from 28831 to 28860\n",
      "now download bulk 962, from 28861 to 28890\n",
      "now download bulk 963, from 28891 to 28920\n",
      "now download bulk 964, from 28921 to 28950\n",
      "now download bulk 965, from 28951 to 28980\n",
      "now download bulk 966, from 28981 to 29010\n",
      "now download bulk 967, from 29011 to 29040\n",
      "now download bulk 968, from 29041 to 29070\n",
      "now download bulk 969, from 29071 to 29100\n",
      "now download bulk 970, from 29101 to 29130\n",
      "now download bulk 971, from 29131 to 29160\n",
      "now download bulk 972, from 29161 to 29190\n",
      "now download bulk 973, from 29191 to 29220\n",
      "now download bulk 974, from 29221 to 29250\n",
      "now download bulk 975, from 29251 to 29280\n",
      "now download bulk 976, from 29281 to 29310\n",
      "now download bulk 977, from 29311 to 29340\n",
      "now download bulk 978, from 29341 to 29370\n",
      "now download bulk 979, from 29371 to 29400\n",
      "now download bulk 980, from 29401 to 29430\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "df_target_entity = pd.read_csv(f'recorder/recorder_{entity}.csv',index_col=0)\n",
    "end = ind+interval\n",
    "\n",
    "while ind < end:\n",
    "    try:\n",
    "        print(f\"now download bulk {ind}, from {ind*bulk_num+1} to {ind*bulk_num+bulk_num}\")\n",
    "        field_names = df_target_entity.loc[ind*bulk_num+1:ind*bulk_num+bulk_num,'field_name']\n",
    "        index = field_names.index\n",
    "        field_lst = [data.find_field(x) for x in list(field_names)]\n",
    "\n",
    "        df_download = data.retrieve_fields(engine=engine, fields=field_lst, coding_values=\"replace\")\n",
    "        df_download = df_download.toPandas()\n",
    "\n",
    "        df_download.to_csv(f'data/{entity}/{ind}.csv',index=False)\n",
    "\n",
    "        df_target_entity.loc[index, 'downloaded']=[True]*len(index)\n",
    "        df_target_entity.loc[index, 'ind']=[ind]*len(index)\n",
    "        df_target_entity.to_csv(f'recorder/recorder_{entity}.csv')\n",
    "    except:\n",
    "        print(f\"error in bulk {ind}\")\n",
    "        fail_list+=[ind]\n",
    "    ind+=1\n",
    "print(f' starttime {start_time}, endtime {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72064ed6-9ae0-46b5-aa1f-143bbf732c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "for file in data/participant/*; do\n",
    "    echo \"$file\"\n",
    "    dx upload \"$file\" --path /\"$file\"\n",
    "    rm \"$file\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6b16d-fa82-42b5-ad98-57269752cb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5f1c7ac-f299-4351-aa5a-ba09c6c35460",
   "metadata": {},
   "source": [
    "ind = 0\n",
    "interval = 5\n",
    "\n",
    "filenames = [f'data/{entity}/{x}.csv' for x in range(ind,ind+interval)]\n",
    "df_compact = pd.concat(map(pd.read_csv, filenames))\n",
    "df_compact.to_pickle(f'data/{entity}/{ind}-{interval-1}.pkl')\n",
    "for file in filenames:\n",
    "    os.remove(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
