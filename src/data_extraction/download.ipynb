{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07264f09-ef47-40bf-b161-68b1e1697ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dxdata\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize dxdata engine\n",
    "engine = dxdata.connect(dialect=\"hive+pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e23bda-3e5d-41f8-a27a-10125b2b2a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = os.popen(\"dx env | grep project- | awk -F '\\t' '{print $2}'\").read().rstrip()\n",
    "record = os.popen(\"dx describe *dataset | grep  record- | awk -F ' ' '{print $2}'\").read().rstrip().split('\\n')[0]\n",
    "DATASET_ID = project + \":\" + record\n",
    "dataset = dxdata.load_dataset(id=DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251038d2-a0b6-4650-85c6-8d192cb02044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = dataset['participant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049c70e-8c6c-45da-9278-4e5237976a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "# Find by field name\n",
    "field_eid = pheno.find_field(name=\"eid\")\n",
    "\n",
    "# Find by exact title\n",
    "field_sex = pheno.find_field(title=\"Sex\")\n",
    "field_age = pheno.find_field(title=\"Age at recruitment\")\n",
    "field_height = pheno.find_field(title=\"Standing height | Instance 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572963c6-5666-426c-b051-231408b37aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Field \"eid\">, <Field \"p50_i0\">, <Field \"p31\">, <Field \"p21022\">]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_list = [field_eid, field_height, field_sex, field_age]\n",
    "field_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72d1a6-d421-4cbe-9b03-323ccade47b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## prepare recorders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca09f190-1802-4a6a-b596-01f51922963c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all_fields = pd.DataFrame(columns = ['entity','field_name','filed_title'])\n",
    "for entity in dataset.entities:\n",
    "    entity_name  = entity.name\n",
    "    \n",
    "    for field in entity.fields:\n",
    "        field_name = field.name\n",
    "        filed_title = field.title\n",
    "        df_all_fields.loc[len(df_all_fields),] = [entity_name,field_name,filed_title]\n",
    "df_all_fields['downloaded']=[False]*len(df_all_fields)\n",
    "df_all_fields.to_csv('recorder_all_fields.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de0b65db-3e49-45db-8d51-bb3badb867ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for entity in df_all_fields['entity'].unique():\n",
    "    df_target_entity = df_all_fields.loc[df_all_fields['entity']==entity,]\n",
    "    df_target_entity.to_csv(f'recorder_{entity}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76eb51-469d-4cf3-a893-48b2820e8025",
   "metadata": {
    "tags": []
   },
   "source": [
    "# data downloading codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd30fd-76d7-4dfa-98e6-fab470d03b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 52,68 is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c7bc0f2-091e-40c0-bb7d-44f78f998b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity='participant'\n",
    "ind = 18\n",
    "interval = 21\n",
    "bulk_num = 30\n",
    "fail_list = [17,18, 52, 68, 179, 815, 816, 820, 828]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05870d05-e08e-434e-ad7d-53323e96c7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now download bulk 18, from 541 to 570\n",
      "error in bulk 18\n",
      "now download bulk 19, from 571 to 600\n",
      "error in bulk 19\n",
      "now download bulk 20, from 601 to 630\n",
      "error in bulk 20\n",
      "now download bulk 21, from 631 to 660\n",
      "error in bulk 21\n",
      "now download bulk 22, from 661 to 690\n",
      "error in bulk 22\n",
      "now download bulk 23, from 691 to 720\n",
      "error in bulk 23\n",
      "now download bulk 24, from 721 to 750\n",
      "error in bulk 24\n",
      "now download bulk 25, from 751 to 780\n",
      "error in bulk 25\n",
      "now download bulk 26, from 781 to 810\n",
      "error in bulk 26\n",
      "now download bulk 27, from 811 to 840\n",
      "error in bulk 27\n",
      "now download bulk 28, from 841 to 870\n",
      "error in bulk 28\n",
      "now download bulk 29, from 871 to 900\n",
      "error in bulk 29\n",
      "now download bulk 30, from 901 to 930\n",
      "error in bulk 30\n",
      "now download bulk 31, from 931 to 960\n",
      "error in bulk 31\n",
      "now download bulk 32, from 961 to 990\n",
      "error in bulk 32\n",
      "now download bulk 33, from 991 to 1020\n",
      "error in bulk 33\n",
      "now download bulk 34, from 1021 to 1050\n",
      "error in bulk 34\n",
      "now download bulk 35, from 1051 to 1080\n",
      "error in bulk 35\n",
      "now download bulk 36, from 1081 to 1110\n",
      "error in bulk 36\n",
      "now download bulk 37, from 1111 to 1140\n",
      "error in bulk 37\n",
      "now download bulk 38, from 1141 to 1170\n",
      "error in bulk 38\n",
      " starttime 2024-02-17 09:06:43.018217, endtime 2024-02-17 09:07:28.956911\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "df_target_entity = pd.read_csv(f'recorder/recorder_{entity}.csv')\n",
    "end = ind+interval\n",
    "ind\n",
    "while ind < end:\n",
    "    try:\n",
    "        print(f\"now download bulk {ind}, from {ind*bulk_num+1} to {ind*bulk_num+bulk_num}\")\n",
    "        field_names = df_target_entity.loc[ind*bulk_num+1:ind*bulk_num+bulk_num,'field_name']\n",
    "        index = field_names.index\n",
    "        field_lst = [data.find_field(x) for x in list(field_names)]\n",
    "\n",
    "        df_download = data.retrieve_fields(engine=engine, fields=field_lst, coding_values=\"replace\")\n",
    "        df_download = df_download.toPandas()\n",
    "\n",
    "        df_download.to_csv(f'data/{entity}/{ind}.csv',index=False)\n",
    "\n",
    "        df_target_entity.loc[index, 'downloaded']=[True]*len(index)\n",
    "        df_target_entity.loc[index, 'ind']=[ind]*len(index)\n",
    "        df_target_entity.to_csv(f'recorder/recorder_{entity}.csv')\n",
    "    except:\n",
    "        print(f\"error in bulk {ind}\")\n",
    "        fail_list+=[ind]\n",
    "    ind+=1\n",
    "print(f' starttime {start_time}, endtime {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34d06dce-4e35-4396-aa96-d4463ba49b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(18,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b6b16d-fa82-42b5-ad98-57269752cb2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now download bulk 17, from 511 to 540\n",
      "[Errno 111] Connection refused\n",
      "error in bulk 17\n",
      "now download bulk 18, from 541 to 570\n",
      "[Errno 111] Connection refused\n",
      "error in bulk 18\n",
      "now download bulk 52, from 1561 to 1590\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m index \u001B[38;5;241m=\u001B[39m field_names\u001B[38;5;241m.\u001B[39mindex\n\u001B[1;32m     12\u001B[0m field_lst \u001B[38;5;241m=\u001B[39m [data\u001B[38;5;241m.\u001B[39mfind_field(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(field_names)]\n\u001B[0;32m---> 14\u001B[0m df_download \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve_fields\u001B[49m\u001B[43m(\u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfields\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfield_lst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoding_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreplace\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m df_download \u001B[38;5;241m=\u001B[39m df_download\u001B[38;5;241m.\u001B[39mtoPandas()\n\u001B[1;32m     17\u001B[0m df_download\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mentity\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mind\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m,index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/dxdata/dataset/dataset.py:2018\u001B[0m, in \u001B[0;36mEntity.retrieve_fields\u001B[0;34m(self, engine, fields, names, titles, filter_sql, coding_values, limit, column_aliases, array_as_string)\u001B[0m\n\u001B[1;32m   1984\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mretrieve_fields\u001B[39m(\u001B[38;5;28mself\u001B[39m, engine, fields\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, names\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, titles\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1985\u001B[0m                     filter_sql\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, coding_values\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m, limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1986\u001B[0m                     column_aliases\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, array_as_string\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m   1988\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build and execute SQL to retrieve fields' database column values.\u001B[39;00m\n\u001B[1;32m   1989\u001B[0m \n\u001B[1;32m   1990\u001B[0m \u001B[38;5;124;03m        Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2015\u001B[0m \u001B[38;5;124;03m        Returns: Spark dataframe\u001B[39;00m\n\u001B[1;32m   2016\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2018\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretrieve_fields\u001B[49m\u001B[43m(\u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mentity_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2019\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mfields\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfields\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtitles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtitles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilter_sql\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilter_sql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2020\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcoding_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoding_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_aliases\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumn_aliases\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2021\u001B[0m \u001B[43m                           \u001B[49m\u001B[43marray_as_string\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marray_as_string\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/dxdata/dataset/dataset.py:115\u001B[0m, in \u001B[0;36mretrieve_fields\u001B[0;34m(engine, dataset, entity_name, fields, names, titles, field_alias_map, filter_sql, coding_values, limit, column_aliases, array_as_string)\u001B[0m\n\u001B[1;32m    110\u001B[0m     filters \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    111\u001B[0m         primary_col: [{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcondition\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubquery\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcohort_query\u001B[39m\u001B[38;5;124m\"\u001B[39m}]\n\u001B[1;32m    112\u001B[0m     }\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquery\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbuilder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DXDatasetQuery\n\u001B[0;32m--> 115\u001B[0m dsq \u001B[38;5;241m=\u001B[39m \u001B[43mDXDatasetQuery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    117\u001B[0m field_name_to_alias_map \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    118\u001B[0m fields \u001B[38;5;241m=\u001B[39m fields \u001B[38;5;129;01mor\u001B[39;00m []\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/dxdata/query/builder.py:35\u001B[0m, in \u001B[0;36mDXDatasetQuery.__init__\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m dataset\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_query_builder_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mHaving \u001B[38;5;241m=\u001B[39m Having(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/dxdata/query/builder.py:101\u001B[0m, in \u001B[0;36mDXDatasetQuery.generate_query_builder_metadata\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m entity_name \u001B[38;5;129;01min\u001B[39;00m all_entities:\n\u001B[1;32m    100\u001B[0m     entity \u001B[38;5;241m=\u001B[39m all_entities[entity_name]\n\u001B[0;32m--> 101\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_sa_tables\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mentity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m     _logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentity: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m : unique name : \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(entity\u001B[38;5;241m.\u001B[39mname, entity\u001B[38;5;241m.\u001B[39mentity_unique_name))\n\u001B[1;32m    103\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m field \u001B[38;5;129;01min\u001B[39;00m entity\u001B[38;5;241m.\u001B[39mfields:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/dxdata/query/builder.py:141\u001B[0m, in \u001B[0;36mDXDatasetQuery.add_sa_tables\u001B[0;34m(self, meta, entity, dataset)\u001B[0m\n\u001B[1;32m    139\u001B[0m database_name \u001B[38;5;241m=\u001B[39m field\u001B[38;5;241m.\u001B[39mget_database_name()\n\u001B[1;32m    140\u001B[0m table \u001B[38;5;241m=\u001B[39m Table(field\u001B[38;5;241m.\u001B[39mtable_name, meta, keep_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, schema\u001B[38;5;241m=\u001B[39mdatabase_name, quote\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 141\u001B[0m \u001B[43mtable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend_column\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_sa_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfield\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m field\u001B[38;5;241m.\u001B[39mis_hierarchical:\n\u001B[1;32m    143\u001B[0m     table\u001B[38;5;241m.\u001B[39mappend_column(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_sa_column(field, field\u001B[38;5;241m.\u001B[39moptimized_column))\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/sql/schema.py:902\u001B[0m, in \u001B[0;36mTable.append_column\u001B[0;34m(self, column, replace_existing)\u001B[0m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mappend_column\u001B[39m(\u001B[38;5;28mself\u001B[39m, column, replace_existing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    877\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Append a :class:`_schema.Column` to this :class:`_schema.Table`.\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \n\u001B[1;32m    879\u001B[0m \u001B[38;5;124;03m    The \"key\" of the newly added :class:`_schema.Column`, i.e. the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    899\u001B[0m \u001B[38;5;124;03m        .. versionadded:: 1.4.0\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 902\u001B[0m     \u001B[43mcolumn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_parent_with_dispatch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    903\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_replacements\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreplace_existing\u001B[49m\n\u001B[1;32m    904\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/sql/base.py:1046\u001B[0m, in \u001B[0;36mSchemaEventTarget._set_parent_with_dispatch\u001B[0;34m(self, parent, **kw)\u001B[0m\n\u001B[1;32m   1045\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_set_parent_with_dispatch\u001B[39m(\u001B[38;5;28mself\u001B[39m, parent, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[0;32m-> 1046\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch\u001B[49m\u001B[38;5;241m.\u001B[39mbefore_parent_attach(\u001B[38;5;28mself\u001B[39m, parent)\n\u001B[1;32m   1047\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_parent(parent, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[1;32m   1048\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch\u001B[38;5;241m.\u001B[39mafter_parent_attach(\u001B[38;5;28mself\u001B[39m, parent)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/event/base.py:321\u001B[0m, in \u001B[0;36mdispatcher.__get__\u001B[0;34m(self, obj, cls)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch\n\u001B[0;32m--> 321\u001B[0m disp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_for_instance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    323\u001B[0m     obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdispatch\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m disp\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/event/base.py:127\u001B[0m, in \u001B[0;36m_Dispatch._for_instance\u001B[0;34m(self, instance)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_for_instance\u001B[39m(\u001B[38;5;28mself\u001B[39m, instance):\n\u001B[1;32m    126\u001B[0m     instance_cls \u001B[38;5;241m=\u001B[39m instance\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_for_class\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstance_cls\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/event/base.py:123\u001B[0m, in \u001B[0;36m_Dispatch._for_class\u001B[0;34m(self, instance_cls)\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_for_class\u001B[39m(\u001B[38;5;28mself\u001B[39m, instance_cls):\n\u001B[0;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minstance_cls\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/event/base.py:83\u001B[0m, in \u001B[0;36m_Dispatch.__init__\u001B[0;34m(self, parent, instance_cls)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;18m__slots__\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_parent\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_instance_cls\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__dict__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_empty_listeners\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     81\u001B[0m _empty_listener_reg \u001B[38;5;241m=\u001B[39m weakref\u001B[38;5;241m.\u001B[39mWeakKeyDictionary()\n\u001B[0;32m---> 83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, parent, instance_cls\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent \u001B[38;5;241m=\u001B[39m parent\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_instance_cls \u001B[38;5;241m=\u001B[39m instance_cls\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "df_target_entity = pd.read_csv(f'recorder/recorder_{entity}.csv')\n",
    "fail_list = [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,52, 68, 179, 815, 816, 820, 828]\n",
    "\n",
    "for ind in fail_list:\n",
    "    try:\n",
    "        print(f\"now download bulk {ind}, from {ind*bulk_num+1} to {ind*bulk_num+bulk_num}\")\n",
    "        field_names = df_target_entity.loc[ind*bulk_num+1:ind*bulk_num+bulk_num,'field_name']\n",
    "        index = field_names.index\n",
    "        field_lst = [data.find_field(x) for x in list(field_names)]\n",
    "\n",
    "        df_download = data.retrieve_fields(engine=engine, fields=field_lst, coding_values=\"replace\")\n",
    "        df_download = df_download.toPandas()\n",
    "\n",
    "        df_download.to_csv(f'data/{entity}/{ind}.csv',index=False)\n",
    "\n",
    "        df_target_entity.loc[index, 'downloaded']=[True]*len(index)\n",
    "        df_target_entity.loc[index, 'ind']=[ind]*len(index)\n",
    "        df_target_entity.to_csv(f'recorder/recorder_{entity}.csv')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"error in bulk {ind}\")\n",
    "        fail_list+=[ind]\n",
    "    ind+=1\n",
    "print(f' starttime {start_time}, endtime {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f1c7ac-f299-4351-aa5a-ba09c6c35460",
   "metadata": {},
   "source": [
    "ind = 0\n",
    "interval = 5\n",
    "\n",
    "filenames = [f'data/{entity}/{x}.csv' for x in range(ind,ind+interval)]\n",
    "df_compact = pd.concat(map(pd.read_csv, filenames))\n",
    "df_compact.to_pickle(f'data/{entity}/{ind}-{interval-1}.pkl')\n",
    "for file in filenames:\n",
    "    os.remove(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
