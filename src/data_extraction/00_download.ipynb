{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07264f09-ef47-40bf-b161-68b1e1697ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dxdata\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize dxdata engine\n",
    "engine = dxdata.connect(dialect=\"hive+pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e23bda-3e5d-41f8-a27a-10125b2b2a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = os.popen(\"dx env | grep project- | awk -F '\\t' '{print $2}'\").read().rstrip()\n",
    "record = os.popen(\"dx describe *dataset | grep  record- | awk -F ' ' '{print $2}'\").read().rstrip().split('\\n')[0]\n",
    "DATASET_ID = project + \":\" + record\n",
    "dataset = dxdata.load_dataset(id=DATASET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251038d2-a0b6-4650-85c6-8d192cb02044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = dataset['participant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842316da-da5a-4a52-a932-bfd9d0902ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"YourAppName\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.mb\", \"24\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max.mb\", \"2000\")\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049c70e-8c6c-45da-9278-4e5237976a40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "# Find by field name\n",
    "field_eid = pheno.find_field(name=\"eid\")\n",
    "\n",
    "# Find by exact title\n",
    "field_sex = pheno.find_field(title=\"Sex\")\n",
    "field_age = pheno.find_field(title=\"Age at recruitment\")\n",
    "field_height = pheno.find_field(title=\"Standing height | Instance 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572963c6-5666-426c-b051-231408b37aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Field \"eid\">, <Field \"p50_i0\">, <Field \"p31\">, <Field \"p21022\">]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_list = [field_eid, field_height, field_sex, field_age]\n",
    "field_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72d1a6-d421-4cbe-9b03-323ccade47b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## prepare recorders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca09f190-1802-4a6a-b596-01f51922963c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all_fields = pd.DataFrame(columns = ['entity','field_name','filed_title'])\n",
    "for entity in dataset.entities:\n",
    "    entity_name  = entity.name\n",
    "    \n",
    "    for field in entity.fields:\n",
    "        field_name = field.name\n",
    "        filed_title = field.title\n",
    "        df_all_fields.loc[len(df_all_fields),] = [entity_name,field_name,filed_title]\n",
    "df_all_fields['downloaded']=[False]*len(df_all_fields)\n",
    "df_all_fields.to_csv('recorder_all_fields.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de0b65db-3e49-45db-8d51-bb3badb867ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for entity in df_all_fields['entity'].unique():\n",
    "    df_target_entity = df_all_fields.loc[df_all_fields['entity']==entity,]\n",
    "    df_target_entity.to_csv(f'recorder_{entity}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb76eb51-469d-4cf3-a893-48b2820e8025",
   "metadata": {
    "tags": []
   },
   "source": [
    "# data downloading codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7bc0f2-091e-40c0-bb7d-44f78f998b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entity='participant'\n",
    "ind = 18\n",
    "interval = 21\n",
    "bulk_num = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6021bc-2755-4632-8fc6-cf8171e9fda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "df_target_entity = pd.read_csv(f'recorder/recorder_{entity}.csv')\n",
    "end = ind+interval\n",
    "ind\n",
    "while ind < end:\n",
    "    try:\n",
    "        print(f\"now download bulk {ind}, from {ind*bulk_num+1} to {ind*bulk_num+bulk_num}\")\n",
    "        field_names = df_target_entity.loc[ind*bulk_num+1:ind*bulk_num+bulk_num,'field_name']\n",
    "        index = field_names.index\n",
    "        field_lst = [data.find_field(x) for x in list(field_names)]\n",
    "\n",
    "        df_download = data.retrieve_fields(engine=engine, fields=field_lst, coding_values=\"replace\")\n",
    "        df_download = df_download.toPandas()\n",
    "\n",
    "        df_download.to_csv(f'data/{entity}/{ind}.csv',index=False)\n",
    "\n",
    "        df_target_entity.loc[index, 'downloaded']=[True]*len(index)\n",
    "        df_target_entity.loc[index, 'ind']=[ind]*len(index)\n",
    "        df_target_entity.to_csv(f'recorder/recorder_{entity}.csv')\n",
    "    except:\n",
    "        print(f\"error in bulk {ind}\")\n",
    "        fail_list+=[ind]\n",
    "    ind+=1\n",
    "print(f' starttime {start_time}, endtime {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42a5e95a-fb23-4b16-9dc1-00d3077068d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fail_list = [52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b87b990e-937e-4e08-bec4-25601852ac1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now download bulk 816, from 24481 to 24510\n",
      " starttime 2024-02-27 09:46:23.682985, endtime 2024-02-27 09:46:48.930128\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "df_target_entity = pd.read_csv(f'recorder/recorder_{entity}.csv')\n",
    "\n",
    "for ind in fail_list:\n",
    "    try:\n",
    "        print(f\"now download bulk {ind}, from {ind*bulk_num+1} to {ind*bulk_num+bulk_num}\")\n",
    "        field_names = df_target_entity.loc[ind*bulk_num+1:ind*bulk_num+bulk_num,'field_name']\n",
    "        index = field_names.index\n",
    "        field_lst = [data.find_field(x) for x in list(field_names)]\n",
    "\n",
    "        df_download = data.retrieve_fields(engine=engine, fields=field_lst, coding_values=\"replace\")\n",
    "        df_download = df_download.toPandas()\n",
    "\n",
    "        df_download.to_csv(f'data/{entity}/{ind}.csv',index=False)\n",
    "\n",
    "        df_target_entity.loc[index, 'downloaded']=[True]*len(index)\n",
    "        df_target_entity.loc[index, 'ind']=[ind]*len(index)\n",
    "        df_target_entity.to_csv(f'recorder/recorder_{entity}.csv')\n",
    "        fail_list.remove(ind)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"error in bulk {ind}\")\n",
    "        \n",
    "    ind+=1\n",
    "print(f' starttime {start_time}, endtime {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "df_target_entity = pd.read_csv(f'recorder/recorder_{entity}.csv')\n",
    "\n",
    "ind = 52\n",
    "try:\n",
    "    print(f\"now download bulk {ind}, from {ind*bulk_num+1} to {ind*bulk_num+bulk_num}\")\n",
    "    field_names = df_target_entity.loc[ind*bulk_num+1:ind*bulk_num+bulk_num,'field_name']\n",
    "    index = field_names.index\n",
    "    field_lst = [data.find_field(x) for x in list(field_names)]\n",
    "\n",
    "    df_download = data.retrieve_fields(engine=engine, fields=field_lst, coding_values=\"replace\")\n",
    "    df_download = df_download.toPandas()\n",
    "\n",
    "    df_download.to_csv(f'data/{entity}/{ind}.csv',index=False)\n",
    "\n",
    "    df_target_entity.loc[index, 'downloaded']=[True]*len(index)\n",
    "    df_target_entity.loc[index, 'ind']=[ind]*len(index)\n",
    "    df_target_entity.to_csv(f'recorder/recorder_{entity}.csv')\n",
    "    fail_list.remove(ind)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"error in bulk {ind}\")\n",
    "\n",
    "\n",
    "print(f' starttime {start_time}, endtime {datetime.now()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "f5f1c7ac-f299-4351-aa5a-ba09c6c35460",
   "metadata": {},
   "source": [
    "ind = 0\n",
    "interval = 5\n",
    "\n",
    "filenames = [f'data/{entity}/{x}.csv' for x in range(ind,ind+interval)]\n",
    "df_compact = pd.concat(map(pd.read_csv, filenames))\n",
    "df_compact.to_pickle(f'data/{entity}/{ind}-{interval-1}.pkl')\n",
    "for file in filenames:\n",
    "    os.remove(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
